# Script: analyze_chapters.py
# Requisitos: pip install openai
# Descripci√≥n: Analiza la transcripci√≥n del podcast para generar cap√≠tulos, descripci√≥n y thumbnail prompt

import os
import json
import warnings
from datetime import timedelta
from dotenv import load_dotenv
from openai import OpenAI

# Ignorar warnings innecesarios
warnings.filterwarnings("ignore")

# Cargar variables de entorno
load_dotenv()

# --- CONFIGURACI√ìN ---
OUTPUT_DIR = "./output"
TRANSCRIPTIONS_DIR = "./output/transcriptions"
METADATA_DIR = "./output/metadata"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def parse_srt(srt_path):
    """
    Lee un archivo .srt y extrae la transcripci√≥n completa con timestamps
    """
    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Parsear bloques de subt√≠tulos
    blocks = content.strip().split('\n\n')
    transcription = []

    for block in blocks:
        lines = block.split('\n')
        if len(lines) >= 3:
            # L√≠nea 1: n√∫mero (ignorar)
            # L√≠nea 2: timestamp
            timestamp = lines[1].split(' --> ')[0]
            # L√≠nea 3+: texto
            text = ' '.join(lines[2:])
            transcription.append({
                'timestamp': timestamp,
                'text': text
            })

    return transcription

def format_transcription_for_ai(transcription):
    """
    Formatea la transcripci√≥n para enviarla a la IA
    """
    formatted = []
    for entry in transcription:
        formatted.append(f"[{entry['timestamp']}] {entry['text']}")
    return '\n'.join(formatted)

def timestamp_to_youtube_format(timestamp_str):
    """
    Convierte timestamp SRT (HH:MM:SS,mmm) a formato YouTube (HH:MM:SS o MM:SS)
    """
    # Remover milisegundos
    time_part = timestamp_str.split(',')[0]
    parts = time_part.split(':')
    hours, minutes, seconds = int(parts[0]), int(parts[1]), int(parts[2])

    # Si no hay horas, usar formato MM:SS
    if hours == 0:
        return f"{minutes}:{seconds:02d}"
    return f"{hours}:{minutes:02d}:{seconds:02d}"

def analyze_with_ai(transcription_text):
    """
    Env√≠a la transcripci√≥n a OpenAI GPT-4o-mini para an√°lisis
    """
    client = OpenAI(api_key=OPENAI_API_KEY)

    prompt = f"""Eres un experto en an√°lisis de contenido para podcasts y YouTube.

A continuaci√≥n te proporcionar√© la transcripci√≥n completa de un episodio de podcast con timestamps.

Tu tarea es:
1. Identificar los temas principales y generar cap√≠tulos tem√°ticos
2. Crear un t√≠tulo clickbait (atractivo pero honesto) para YouTube
3. Escribir una descripci√≥n profesional del episodio
4. Generar un prompt detallado para crear la imagen/thumbnail 16:9

TRANSCRIPCI√ìN:
{transcription_text}

---

Por favor, responde √öNICAMENTE con un JSON v√°lido en este formato exacto:

{{
  "title": "T√≠tulo clickbait del episodio (m√°ximo 100 caracteres)",
  "chapters": [
    {{
      "timestamp": "00:00",
      "title": "Introducci√≥n al tema",
      "description": "Breve descripci√≥n de qu√© se habla"
    }},
    {{
      "timestamp": "05:30",
      "title": "Segundo tema",
      "description": "Descripci√≥n del segundo bloque"
    }}
  ],
  "description": "Descripci√≥n completa del episodio para YouTube (3-5 p√°rrafos, incluye los temas principales)",
  "thumbnail_prompt": "Prompt detallado para DALL-E 3 o Midjourney describiendo la imagen ideal para el thumbnail en formato 16:9. Debe ser visual, espec√≠fico y atractivo.",
  "clips": [
    {{
      "start": "02:15",
      "end": "03:45",
      "title": "Momento destacado 1",
      "reason": "Por qu√© este fragmento es bueno para un clip corto"
    }},
    {{
      "start": "08:20",
      "end": "10:00",
      "title": "Momento destacado 2",
      "reason": "Por qu√© este fragmento funciona como clip"
    }}
  ]
}}

IMPORTANTE:
- Los timestamps deben estar en formato MM:SS o HH:MM:SS
- Identifica entre 3-7 cap√≠tulos seg√∫n la duraci√≥n
- Sugiere 2-5 clips potenciales (m√°ximo 2 minutos cada uno)
- El t√≠tulo debe ser atractivo pero no sensacionalista
- La descripci√≥n debe ser informativa y profesional
- El prompt del thumbnail debe ser muy visual y descriptivo"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Eres un experto en an√°lisis de contenido para podcasts. Siempre respondes con JSON v√°lido."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)
        return result

    except Exception as e:
        print(f"‚ùå ERROR en la llamada a OpenAI: {e}")
        return None

def generate_youtube_description(analysis):
    """
    Genera el archivo de descripci√≥n formateado para YouTube
    """
    lines = []

    # T√≠tulo
    lines.append("=" * 80)
    lines.append("T√çTULO DEL VIDEO")
    lines.append("=" * 80)
    lines.append(analysis['title'])
    lines.append("")

    # Descripci√≥n
    lines.append("=" * 80)
    lines.append("DESCRIPCI√ìN")
    lines.append("=" * 80)
    lines.append(analysis['description'])
    lines.append("")

    # Cap√≠tulos
    lines.append("=" * 80)
    lines.append("CAP√çTULOS (YouTube Timestamps)")
    lines.append("=" * 80)
    for chapter in analysis['chapters']:
        lines.append(f"{chapter['timestamp']} - {chapter['title']}")
    lines.append("")

    # Thumbnail prompt
    lines.append("=" * 80)
    lines.append("PROMPT PARA THUMBNAIL/PORTADA (16:9)")
    lines.append("=" * 80)
    lines.append(analysis['thumbnail_prompt'])
    lines.append("")
    lines.append("üí° Usa este prompt en DALL-E 3, Midjourney, o cualquier generador de im√°genes IA")
    lines.append("=" * 80)

    return '\n'.join(lines)

def main():
    print("=" * 80)
    print("  ANALIZADOR DE CAP√çTULOS Y METADATA - AI PODCAST PRODUCER")
    print("=" * 80)

    # 1. Validar API Key
    if not OPENAI_API_KEY:
        print("\n‚ùå ERROR: No se encontr√≥ OPENAI_API_KEY en el archivo .env")
        print("Por favor, agrega la l√≠nea: OPENAI_API_KEY=sk-tu_clave_aqui")
        print("\nPuedes obtener tu API key en: https://platform.openai.com/api-keys")
        return

    # 2. Buscar archivo .srt en /output/transcriptions
    print("\n--> Paso 1/5: Buscando archivo de subt√≠tulos...")
    srt_files = [f for f in os.listdir(TRANSCRIPTIONS_DIR) if f.endswith('.srt') and os.path.isfile(os.path.join(TRANSCRIPTIONS_DIR, f))]

    if len(srt_files) == 0:
        print("‚ùå ERROR: No se encontr√≥ ning√∫n archivo .srt en /output/transcriptions")
        print("Por favor, ejecuta primero: python generate_subtitles.py")
        return
    elif len(srt_files) > 1:
        print("‚ö†Ô∏è  Se encontraron m√∫ltiples archivos .srt:")
        for idx, file in enumerate(srt_files, 1):
            print(f"   {idx}. {file}")
        print(f"\nUsando el m√°s reciente: {srt_files[0]}")

    srt_path = os.path.join(TRANSCRIPTIONS_DIR, srt_files[0])
    filename_base = os.path.splitext(srt_files[0])[0]

    print(f"‚úì Archivo encontrado: {srt_files[0]}")

    # 3. Parsear transcripci√≥n
    print("\n--> Paso 2/5: Leyendo transcripci√≥n...")
    try:
        transcription = parse_srt(srt_path)
        total_entries = len(transcription)
        print(f"‚úì Se cargaron {total_entries} segmentos de transcripci√≥n")

        # Calcular duraci√≥n aproximada
        if transcription:
            last_timestamp = transcription[-1]['timestamp']
            print(f"‚úì Duraci√≥n aproximada: {last_timestamp}")
    except Exception as e:
        print(f"‚ùå ERROR al leer el archivo .srt: {e}")
        return

    # 4. Formatear para IA
    print("\n--> Paso 3/5: Preparando an√°lisis con IA...")
    transcription_text = format_transcription_for_ai(transcription)

    # Calcular tokens aproximados (4 caracteres ‚âà 1 token)
    estimated_tokens = len(transcription_text) // 4
    estimated_cost = (estimated_tokens / 1_000_000) * 0.15  # $0.15 por mill√≥n de tokens de entrada

    print(f"   Caracteres de transcripci√≥n: {len(transcription_text):,}")
    print(f"   Tokens estimados: ~{estimated_tokens:,}")
    print(f"   Costo estimado: ~${estimated_cost:.4f} USD")

    # 5. Analizar con IA
    print("\n--> Paso 4/5: Analizando contenido con GPT-4o-mini...")
    print("   (Esto puede tardar 10-30 segundos dependiendo de la longitud)")

    analysis = analyze_with_ai(transcription_text)

    if not analysis:
        print("‚ùå ERROR: No se pudo completar el an√°lisis")
        return

    print(f"‚úì An√°lisis completado exitosamente")
    print(f"   ‚Ä¢ T√≠tulo generado: {analysis['title'][:60]}...")
    print(f"   ‚Ä¢ Cap√≠tulos detectados: {len(analysis['chapters'])}")
    print(f"   ‚Ä¢ Clips sugeridos: {len(analysis.get('clips', []))}")

    # 6. Generar archivos de salida
    print("\n--> Paso 5/5: Generando archivos de salida...")

    # Crear directorio metadata si no existe
    os.makedirs(METADATA_DIR, exist_ok=True)

    try:
        # A. chapters.json (Cap√≠tulos estructurados)
        chapters_path = os.path.join(METADATA_DIR, f"{filename_base}_chapters.json")
        with open(chapters_path, 'w', encoding='utf-8') as f:
            json.dump(analysis['chapters'], f, indent=2, ensure_ascii=False)
        print(f"‚úì {chapters_path}")

        # B. clips_guide.json (Gu√≠a de clips para redes sociales)
        if 'clips' in analysis and analysis['clips']:
            clips_path = os.path.join(METADATA_DIR, f"{filename_base}_clips.json")
            with open(clips_path, 'w', encoding='utf-8') as f:
                json.dump(analysis['clips'], f, indent=2, ensure_ascii=False)
            print(f"‚úì {clips_path}")

        # C. youtube_description.txt (Descripci√≥n completa lista para copiar)
        description_path = os.path.join(METADATA_DIR, f"{filename_base}_youtube.txt")
        description_text = generate_youtube_description(analysis)
        with open(description_path, 'w', encoding='utf-8') as f:
            f.write(description_text)
        print(f"‚úì {description_path}")

        # D. metadata.json (Todo junto para referencia)
        metadata_path = os.path.join(METADATA_DIR, f"{filename_base}_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)
        print(f"‚úì {metadata_path}")

    except Exception as e:
        print(f"‚ùå ERROR al guardar archivos: {e}")
        return

    # 7. Resumen final
    print("\n" + "=" * 80)
    print("‚úÖ ¬°AN√ÅLISIS COMPLETADO!")
    print("=" * 80)
    print(f"\nüì∫ T√çTULO SUGERIDO:")
    print(f"   {analysis['title']}")
    print(f"\nüìÇ ARCHIVOS GENERADOS:")
    print(f"   1. {filename_base}_youtube.txt     ‚Üí Copiar/pegar en YouTube")
    print(f"   2. {filename_base}_chapters.json   ‚Üí Cap√≠tulos estructurados")
    print(f"   3. {filename_base}_clips.json      ‚Üí Clips para redes sociales")
    print(f"   4. {filename_base}_metadata.json   ‚Üí Metadata completa")
    print(f"\nüí° SIGUIENTE PASO:")
    print(f"   1. Abre '{filename_base}_youtube.txt' para ver toda la info")
    print(f"   2. Usa el prompt del thumbnail para generar la portada")
    print(f"   3. Copia los cap√≠tulos y descripci√≥n a YouTube")
    print("=" * 80)

if __name__ == "__main__":
    main()
