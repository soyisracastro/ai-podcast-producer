# AI Podcast Producer

An automated workflow to convert **NotebookLM** audio research into a fully produced video podcast with synchronized avatars (HeyGen) and multi-camera editing.

## ğŸš€ Overview

This toolchain solves the manual bottleneck of editing conversational AI podcasts. It takes a single audio file (generated by Google NotebookLM), identifies the speakers, splits the audio into synchronized tracks for avatar generation, and automatically assembles a final video with "TV-style" camera cuts based on who is speaking.

### Workflow
1.  **Input:** Single audio file (e.g., `m4a` from NotebookLM).
2.  **Processing (`split_audios.py`):** 
    *   Converts audio format.
    *   Performs Speaker Diarization (AI detection of who speaks when).
    *   Generates two synchronized audio tracks with silence gaps.
    *   Generates an `editing_guide.json` with timestamps.
3.  **Visual Generation (HeyGen):** 
    *   *Manual Step:* Upload tracks to HeyGen to generate avatar videos.
4.  **Assembly (`assemble_video.py`):** 
    *   Reads the JSON guide.
    *   Stitches the two videos together using multi-cam logic.
    *   Handles reaction shots (filling silence with listening gestures).

## ğŸ› ï¸ Prerequisites

## ğŸ macOS Users (M1/M2/M3)

Running AI models locally on Apple Silicon requires a specific setup (Python 3.10 + pinned dependencies). 
ğŸ‘‰ **Please read [SETUP_MAC.md](SETUP_MAC.md) for detailed installation instructions.**

*   **Python 3.8+**
*   **FFmpeg** (Required for audio processing)
    *   Mac: `brew install ffmpeg`
    *   Ubuntu: `sudo apt install ffmpeg`
    *   Windows: Install via Chocolatey or download binaries.
*   **Hugging Face Account** (For pyannote.audio model)

## ğŸ“¦ Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/soyisracastro/ai-podcast-producer.git
    cd ai-podcast-producer
    ```

2.  **Create a virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Windows: venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: Create a `requirements.txt` with: `pyannote.audio`, `pydub`, `torch`, `python-dotenv`, `moviepy`)*

4.  **Environment Setup:**
    Create a `.env` file in the root directory (copy from `.env.example`):
    ```bash
    cp .env.example .env
    ```

    Edit `.env` and add your API keys:
    ```ini
    # Required for speaker diarization (split_audios.py)
    HF_TOKEN=hf_your_token_here

    # Optional - for chapter analysis (analyze_chapters.py)
    OPENAI_API_KEY=sk-your_openai_key_here
    ```

    **Important:**
    - You must accept the user agreement for `pyannote/speaker-diarization-3.1` ([click here](https://huggingface.co/pyannote/speaker-diarization-3.1)) and `pyannote/segmentation-3.0` ([click here](https://huggingface.co/pyannote/segmentation-3.0)) on Hugging Face Hub.
    - OpenAI API key is only needed if you want to use the chapter analysis feature.

## ğŸ¬ Usage (Step-by-Step)

### Step 1: Audio Analysis & Splitting
Place your NotebookLM audio file (`.m4a` format) in the `/input` folder. The script will automatically detect it.

```bash
# The script will automatically find the .m4a file in /input
python split_audios.py
```

Output:

- track_host_A.mp3
- track_host_B.mp3
- editing_guide.json

**âš ï¸ Troubleshooting:** If you notice incorrect speaker assignments (same avatar with different voices), see [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) for debugging and fixing tools.

### Step 2: Video Generation (HeyGen)

- Log in to HeyGen.
- Create two videos using the generated mp3 tracks.
- Host A: Choose an avatar for the first voice.
- Host B: Choose an avatar for the second voice.
- Download the resulting videos and save them in the root folder as:
  - host_a_video.mp4
  - host_b_video.mp4

### Step 3: Generate Subtitles (Optional)
Generate subtitles automatically from the original audio using AI transcription.

```bash
python generate_subtitles.py
```

Output:
- `{filename}.srt` (Subtitle file with timestamps for video editors and YouTube)
- `{filename}.txt` (Plain text transcription in one continuous line)

**Note:** This uses OpenAI Whisper locally (no API cost). The first run will download the AI model (~100MB for 'base' model).

### Step 3b: Analyze Chapters & Generate Metadata (Optional but Recommended)
Use AI to analyze the transcript and generate YouTube chapters, title, description, and thumbnail prompt.

```bash
python analyze_chapters.py
```

**Prerequisites:** Add `OPENAI_API_KEY` to your `.env` file (see [.env.example](.env.example))

Output:
- `{filename}_youtube.txt` - Complete YouTube metadata (title, description, chapters, thumbnail prompt)
- `{filename}_chapters.json` - Structured chapter data with timestamps
- `{filename}_clips.json` - Suggested clips for social media (legacy)
- `{filename}_metadata.json` - Complete analysis data with viral_clips and chapter_clips
- `{filename}_content_table.csv` - **NEW:** Content table with SEO metadata for all clips
- `{filename}_calendar.csv` - **NEW:** Auto-generated weekly publication calendar

**Cost:** ~$0.01-0.03 USD per episode (using GPT-4o-mini)

**New Features (2025 Update):**
- ğŸ¯ **Two Clip Types**: Viral clips (15-60s) for social media + Chapter clips (full chapters) for YouTube
- ğŸ“Š **SEO Optimization**: Each clip gets unique SEO title, description, and thumbnail prompt
- ğŸ“… **Smart Calendar**: Auto-assigns clips to optimal weekly time slots
- ğŸ”¢ **Dynamic Clip Count**: AI decides number of viral clips based on episode length (4-15 clips)

### Step 3c: Generate Visual Markers (Optional - For Dynamic Editing)
Automatically identify key moments for visual elements (images, infographics, text overlays) to keep audience engaged.

```bash
python generate_visual_markers.py
```

**Prerequisites:** Add `OPENAI_API_KEY` to your `.env` file

Output:
- `{filename}_visual_guide.txt` - Complete guide with image prompts and infographic specs
- `{filename}_visual_timeline.csv` - Timeline for importing into video editors
- `{filename}_visual_markers.json` - Structured visual data

**Features:**
- ğŸ–¼ï¸ Photo-realistic image prompts (DALL-E/Midjourney ready)
- ğŸ“Š Infographic specifications for complex data (calculations, comparisons)
- ğŸ’¬ Text overlay suggestions for key phrases
- â±ï¸ Strategic timestamps to maintain audience attention

**Cost:** ~$0.01-0.03 USD per episode (using GPT-4o-mini)

### Step 4: Automated Assembly
Run the assembler to stitch the final episode.

```bash
python assemble_video.py
```

Output:
- final_episode.mp4

### Step 4b: Generate Clips Automatically (Optional - NEW!)
Extract viral clips and chapter clips automatically from the final video based on AI analysis.

```bash
python generate_clips.py
```

**Prerequisites:**
- Must have run `analyze_chapters.py` (Step 3b) to generate metadata
- Must have the final video in `/input` folder (from Step 4)

Output:
- `/output/viral_clips/viral_clip_{title}.mp4` - Short viral clips (15-60s) for TikTok/Instagram/Facebook
- `/output/clips/clip_{title}.mp4` - Full chapter clips for YouTube

**Features:**
- ğŸ¬ **Automated Extraction**: Uses MoviePy to cut clips based on timestamps from metadata.json
- ğŸ“± **Ready for Social Media**: Viral clips are optimized for short-form platforms
- ğŸ“º **YouTube Chapters**: Full chapter clips for viewers who want specific topics
- ğŸ“ **SEO-Optimized Names**: File names use SEO titles from the analysis

**Note:** This saves hours of manual clip editing! The script automatically:
1. Finds the metadata.json with clip timestamps
2. Locates the final video file
3. Extracts all viral and chapter clips
4. Saves them with descriptive, SEO-friendly names

### Step 4c: Sync Publication Calendar to Notion (Optional - NEW!)
Automatically sync your publication calendar to a Notion database for easy content management.

```bash
python sync_to_notion.py
```

**Prerequisites:**
- Must have run `analyze_chapters.py` (Step 3b) to generate the calendar CSV
- Notion integration token and database ID configured (see [NOTION_SETUP.md](NOTION_SETUP.md))

Output:
- All calendar entries synced to your Notion database
- Each entry includes: Day, Time, Content Type, Title, Platform, Notes, and a "Published" checkbox

**Features:**
- ğŸ“… **Automated Sync**: Imports publication calendar directly from CSV to Notion
- âœ… **Publication Tracking**: Checkbox field to mark content as published
- ğŸ”„ **Smart Updates**: Archives old entries and syncs fresh data
- ğŸ“Š **Content Management**: Filter and organize your publication schedule in Notion

**Setup:** See [NOTION_SETUP.md](NOTION_SETUP.md) for step-by-step configuration instructions (5 minutes)

**Workflow:**
1. Run `analyze_chapters.py` to generate calendar
2. Run `sync_to_notion.py` to sync to Notion
3. Open your Notion database to view the publication schedule
4. Mark clips as "Published" after posting to social media
5. Use Notion views to filter by platform, day, or publication status

### Step 5: Archive & Clean (Optional)

After completing an episode, archive the work and prepare for the next project:

```bash
# Archive with custom name
./archive_and_clean.sh "episodio_01_intro_ia"

# Or let it auto-detect the name from the .m4a file in /input
./archive_and_clean.sh
```

This will:
- Create a `.zip` file in the `/archives` directory
- Clean `/input` and `/output` directories
- Prepare the workspace for a new episode

**Optional - Upload to cloud:**
```bash
# Upload to AWS S3
./upload_to_s3.sh episodio_01_intro_ia.zip my-podcast-bucket

# Or manually copy to OneDrive/Google Drive
cp archives/episodio_01_intro_ia.zip ~/OneDrive/Podcasts/
```

ğŸ“– For detailed archiving instructions, see [ARCHIVE_GUIDE.md](docs/ARCHIVE_GUIDE.md)

## ğŸ“š Documentation

Complete documentation is available in the `/docs` folder:

| Document | Description | When to Use |
|----------|-------------|-------------|
| [Quick Start Debug](docs/QUICK_START_DEBUG.md) | 3-step debugging guide | Speaker assignment issues |
| [Troubleshooting](docs/TROUBLESHOOTING.md) | Complete problem-solving guide | Detailed solutions |
| [Speaker Detection Improvements](docs/SPEAKER_DETECTION_IMPROVEMENTS.md) | Technical details | Advanced users |
| [Archive Guide](docs/ARCHIVE_GUIDE.md) | Archiving workflow | After completing episodes |

**â†’ See [docs/README.md](docs/README.md) for complete documentation index**

---

## ğŸ“‚ Project Structure

```text
ai-podcast-producer/
â”œâ”€â”€ split_audios.py           # Handles diarization and audio splitting
â”œâ”€â”€ generate_subtitles.py     # Generates .srt subtitles and .txt transcription
â”œâ”€â”€ analyze_chapters.py       # Analyzes transcript and generates YouTube metadata
â”œâ”€â”€ generate_visual_markers.py # Generates visual prompts (images, infographics)
â”œâ”€â”€ generate_clips.py         # ğŸ¬ Extracts viral and chapter clips from video
â”œâ”€â”€ sync_to_notion.py         # ğŸ“… Syncs publication calendar to Notion
â”œâ”€â”€ assemble_video.py         # Handles video stitching and editing logic
â”œâ”€â”€ archive_and_clean.sh      # Archive & clean input/output directories
â”œâ”€â”€ upload_to_s3.sh           # Upload archives to AWS S3 (optional)
â”œâ”€â”€ debug_diarization.py      # ğŸ” Analyze speaker assignment quality
â”œâ”€â”€ fix_speaker_assignment.py # ğŸ”§ Fix incorrect speaker assignments
â”œâ”€â”€ editing_guide.json        # Generated map of cuts (Do not edit manually)
â”œâ”€â”€ .env                      # API Keys (Excluded from Git)
â”œâ”€â”€ .env.example              # Template for environment variables
â”œâ”€â”€ .gitignore                # Git configuration
â”œâ”€â”€ README.md                 # Main documentation
â”œâ”€â”€ NOTION_SETUP.md           # ğŸ“‹ Notion integration setup guide
â”œâ”€â”€ docs/                     # ğŸ“š Complete documentation
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md    # Debugging & fixing speaker issues
â”‚   â”œâ”€â”€ QUICK_START_DEBUG.md  # Quick debugging guide (3 steps)
â”‚   â”œâ”€â”€ SPEAKER_DETECTION_IMPROVEMENTS.md  # Technical details
â”‚   â””â”€â”€ ARCHIVE_GUIDE.md      # Archive & backup workflow
â”œâ”€â”€ input/                    # Input files directory
â”œâ”€â”€ output/                   # Output files directory
â”‚   â”œâ”€â”€ clips/                # Generated chapter clips
â”‚   â”œâ”€â”€ viral_clips/          # Generated viral clips (15-60s)
â”‚   â””â”€â”€ metadata/             # Generated metadata and calendars
â””â”€â”€ archives/                 # Local backup archives (git-ignored)
```

## ğŸ”® Roadmap

- [x] Speaker Diarization & Audio Splitting
- [x] Automated Multi-Cam Video Assembly
- [x] Automatic Subtitle Generation (.srt)
- [x] AI Chapter Analysis & YouTube Metadata Generation (title, description, chapters, thumbnail prompt)
- [x] Clip Extraction: Automatically extract viral and chapter clips for social media
- [x] SEO Optimization: Auto-generated SEO titles, descriptions, and thumbnail prompts
- [x] Publication Calendar: Weekly content schedule with optimal posting times
- [x] Notion Integration: Sync publication calendar to Notion for content management
- [ ] HeyGen API Integration: Automate the video generation and download process
- [ ] YouTube Publishing: Upload final video via YouTube Data API
- [ ] Social Media API Integration: Auto-publish clips to TikTok, Instagram, Facebook